{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "# !pip install kaggle\n",
    "# !pip install kagglehub\n",
    "# \n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install Pillow\n",
    "# !pip install scikit-learn\n",
    "# \n",
    "# !pip install seaborn\n",
    "# \n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install torchsummary\n",
    "\n",
    "# !pip install joblib"
   ],
   "id": "574d4b877ba6efb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "36485884df5b0cd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Path to dataset files: C:\\Users\\CindyHong\\.cache\\kagglehub\\datasets\\lantian773030\\pokemonclassification\\versions\\1\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "# Copy from kaggle\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lantian773030/pokemonclassification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ],
   "id": "f5a8f3b01d2abc9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import ImageOps,ImageEnhance\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import random_split\n",
    "import scipy\n",
    "\n",
    "from torchvision import models\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from joblib import dump, load\n",
    "import gc\n"
   ],
   "id": "baf73b13919666c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": "np.random.seed(2024)",
   "id": "f379814e4e14e97a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\CindyHong\\\\.cache\\\\kagglehub\\\\datasets\\\\lantian773030\\\\pokemonclassification\\\\versions\\\\1\\\\PokemonData'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5,
   "source": [
    "# Setting dataset path\n",
    "path = os.path.join(path,'PokemonData')\n",
    "path"
   ],
   "id": "2a1741b6ae42a3aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 6,
   "source": "class_list = pd.read_csv('https://raw.githubusercontent.com/cecilia-lin/CSE151A_Pokemon_Classification/refs/heads/main/class_sheet.csv')",
   "id": "3d84a0ba1e62318c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 9,
   "source": [
    "# Removing all classes with bad data\n",
    "class_list = class_list[class_list['Bad_Data'] != 1]"
   ],
   "id": "9d68feb9f99ca89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 10,
   "source": [
    "# Getting Pokemons that are winged and not winged\n",
    "winged = class_list[class_list['Winged'] == 1]\n",
    "winged = winged['Pokemon']\n",
    "not_winged = class_list[class_list['Not_Winged'] == 1]\n",
    "not_winged = not_winged['Pokemon']"
   ],
   "id": "20c4ee04adde4375"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.asp',\n",
       " \".jpg')\",\n",
       " '.jpg~c200',\n",
       " '.sb-334870d9-FK2TVI',\n",
       " '.sb-334870d9-nlD60H',\n",
       " '.svg'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11,
   "source": [
    "# Making a data frame that has the image paths and their classifcation\n",
    "images = []\n",
    "wrong_extensions = []\n",
    "\n",
    "for folder in winged:\n",
    "    image_names = os.listdir(os.path.join(path,folder))\n",
    "    for image in image_names:\n",
    "        file_extension = os.path.splitext(image)[1]\n",
    "        # Sanity check to make sure all file paths exist\n",
    "        if file_extension not in valid_extensions:\n",
    "            wrong_extensions.append(file_extension)\n",
    "            continue\n",
    "        image_path = os.path.join(path,folder,image)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(image_path)\n",
    "            continue\n",
    "        with Image.open(image_path) as img:\n",
    "            img = np.array(img)\n",
    "            images.append({'Image': img, 'Source': 'Winged'})\n",
    "            \n",
    "for folder in not_winged:\n",
    "    image_names = os.listdir(os.path.join(path,folder))\n",
    "    for image in image_names:\n",
    "        file_extension = os.path.splitext(image)[1]\n",
    "        # Sanity check to make sure all file paths exist\n",
    "        if file_extension not in valid_extensions:\n",
    "            wrong_extensions.append(file_extension)\n",
    "            continue\n",
    "        image_path = os.path.join(path,folder,image)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(image_path)\n",
    "            continue\n",
    "        with Image.open(image_path) as img:\n",
    "            img = np.array(img)\n",
    "            images.append({'Image': img, 'Source': 'Not Winged'})\n",
    "            \n",
    "df = pd.DataFrame(images)\n",
    "set(wrong_extensions)"
   ],
   "id": "2e5b014da27c300e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 12,
   "source": [
    "# Sanity check to make sure there are only 2 classes\n",
    "for index, row in df.iterrows():\n",
    "    if row['Source'] not in ['Winged', 'Not Winged']:\n",
    "        print(row)"
   ],
   "id": "c271548110944a99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Preprocessing",
   "id": "4ed29243f7bd6e08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 19,
   "source": [
    "# Normalizing function\n",
    "def zscore(img,default = False):\n",
    "    '''\n",
    "    Apply Z-score normalization to an image.\n",
    "\n",
    "    Parameters:\n",
    "    - img (numpy array): The input image array.\n",
    "    - default (bool): Whether to use default ImageNet mean and std.\n",
    "\n",
    "    Returns:\n",
    "    - img (numpy array): The normalized image array.\n",
    "    '''\n",
    "    img = img.astype(np.float32)\n",
    "    for c in range(img.shape[2]):\n",
    "        if not default:\n",
    "            mean = img[:,:,c].mean()\n",
    "            std = img[:,:,c].std()\n",
    "        else:\n",
    "            # Use default mean and std from ImageNet\n",
    "            mean=[0.485, 0.456, 0.406][c]\n",
    "            std=[0.229, 0.224, 0.225][c]\n",
    "        if std > 0:\n",
    "            img[:,:,c] = (img[:,:,c] - mean) / std\n",
    "        else:\n",
    "            img[:,:,c] = (img[:,:,c] - mean)\n",
    "    return img\n",
    "\n",
    "def minmax(img):\n",
    "    '''\n",
    "    Apply Min-Max normalization to an image.\n",
    "\n",
    "    Parameters:\n",
    "    - img (numpy array): The input image array.\n",
    "\n",
    "    Returns:\n",
    "    - img (numpy array): The normalized image array.\n",
    "    '''\n",
    "    img = img.astype(np.float32)\n",
    "    for c in range(img.shape[2]):\n",
    "        max = img[:,:,c].max()\n",
    "        min = img[:,:,c].min()\n",
    "        img[:,:,c] = (img[:,:,c] - min) / (max - min)\n",
    "    return img"
   ],
   "id": "3d7b1c11a81efbda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 20,
   "source": [
    "# Function to preprocess images\n",
    "def preprocess(df, pattern, default=False, batch_size=50):\n",
    "    '''\n",
    "    Preprocess images by resizing, converting to grayscale or RGB, and normalizing pixel values.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): DataFrame containing images and labels.\n",
    "    - pattern (str): Normalization pattern ('Zscore', 'Minmax', 'Grayscale').\n",
    "    - default (bool): Whether to use default mean and std for Z-score normalization.\n",
    "    - batch_size (int): Number of images to process in each batch.\n",
    "\n",
    "    Returns:\n",
    "    - X (numpy array): Array of preprocessed images.\n",
    "    - y (numpy array): Array of corresponding labels.\n",
    "    '''\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    new_size = (224, 224)\n",
    "\n",
    "     # Process images in batches to manage memory usage\n",
    "    for start in range(0, len(df), batch_size):\n",
    "        batch_df = df.iloc[start:start + batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for _, row in batch_df.iterrows():\n",
    "            # Resize images to 224 x 224\n",
    "            img = Image.fromarray(row['Image']).resize(new_size)\n",
    "            if pattern == 'Grayscale':\n",
    "                # Convert images to grayscale\n",
    "                img = img.convert('L')\n",
    "                img = np.array(img) / 255.0\n",
    "            else:\n",
    "                img = img.convert('RGB')\n",
    "                img = np.array(img)\n",
    "                # Zscore normalization\n",
    "                if pattern == 'Zscore':\n",
    "                    img = zscore(img, default=default)\n",
    "                # Minmax normalization\n",
    "                elif pattern == 'Minmax':\n",
    "                    img = minmax(img)\n",
    "\n",
    "            X_batch.append(img)\n",
    "            y_batch.append(1 if row['Source'] == 'Winged' else 0)\n",
    "        \n",
    "        X.append(np.array(X_batch))\n",
    "        y.append(np.array(y_batch))\n",
    "        \n",
    "        # Release memory\n",
    "        del X_batch, y_batch\n",
    "        gc.collect()\n",
    "    \n",
    "    # Concatenate batches into full arrays\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    return X, y # X shape: (n_samples, 224, 224, 3) or (n_samples, 224, 224)"
   ],
   "id": "6324a40677d8745c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 27,
   "source": [
    "######## We can also use some optimization methods to train on imbalanced dataset ########\n",
    "# Balancing the data set by random sampling\n",
    "def random_sample(X,y,size=600):\n",
    "    '''\n",
    "    Balance the dataset by randomly sampling equal numbers of images from each class.\n",
    "\n",
    "    Parameters:\n",
    "    - X (numpy array): Array of images.\n",
    "    - y (numpy array): Array of labels.\n",
    "\n",
    "    Returns:\n",
    "    - X (numpy array): Balanced array of images.\n",
    "    - y (numpy array): Balanced array of labels.\n",
    "    '''\n",
    "    id_not_winged = np.where(y == 0)[0]\n",
    "    id_winged = np.where(y == 1)[0]\n",
    "    sample_not_winged = np.random.choice(id_not_winged, size, replace=False)\n",
    "    sample_winged = np.random.choice(id_winged, size, replace=False)\n",
    "    sample = np.concatenate((sample_not_winged, sample_winged), axis=0)\n",
    "    X = X[sample]\n",
    "    y = y[sample]\n",
    "    return X,y\n",
    "######## We can also use some optimization methods to train on imbalanced dataset ########\n",
    "\n",
    "# Creating Train/Validate/Test splits (80/10/10)\n",
    "def random_split(X,y,train_size=0.8):\n",
    "    '''\n",
    "    Split the data into training, validation, and test sets (80% train, 10% val, 10% test).\n",
    "\n",
    "    Parameters:\n",
    "    - X (numpy array): Array of images.\n",
    "    - y (numpy array): Array of labels.\n",
    "\n",
    "    Returns:\n",
    "    - X_train, X_val, X_test: Split arrays of images.\n",
    "    - y_train, y_val, y_test: Split arrays of labels.\n",
    "    '''\n",
    "    #Split into training and temporary sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=1-train_size, random_state=2024, stratify=y)\n",
    "\n",
    "    #Split the temporary set into validation and test sets\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=2024, stratify=y_temp)\n",
    "    return X_train, X_val, X_test, y_train, y_val,y_test\n",
    "\n",
    "# X , y = random_sample(X,y)\n",
    "# X_train, X_val, X_test, y_train, y_val,y_test = random_split(X,y)"
   ],
   "id": "3c70296aac232edb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 28,
   "source": [
    "# Augmentation function\n",
    "# Our resized image doesn't have enough space for shearing or zooming\n",
    "def augmentation(img,pattern,img_size=(224,224),horizontal_flip=True,vertical_flip=False,rotation_range=20, horizontal_shift=0.2, vertical_shift=0.2):\n",
    "    '''\n",
    "    Apply data augmentation techniques to a single image.\n",
    "\n",
    "    Parameters:\n",
    "    - img (numpy array): Input image.\n",
    "    - pattern (str): Normalization pattern used ('Zscore', 'Minmax', 'Grayscale').\n",
    "    - img_size (tuple): Desired output image size.\n",
    "    - horizontal_flip (bool): Whether to apply horizontal flip.\n",
    "    - vertical_flip (bool): Whether to apply vertical flip.\n",
    "    - rotation_range (int): Range of degrees for random rotations.\n",
    "    - horizontal_shift (float): Fraction of width for horizontal shift.\n",
    "    - vertical_shift (float): Fraction of height for vertical shift.\n",
    "\n",
    "    Returns:\n",
    "    - img (numpy array): Augmented image.\n",
    "    '''\n",
    "    if img.dtype == np.float32:\n",
    "        # Convert image back to uint8 for PIL processing\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    if pattern != 'Grayscale':\n",
    "        # Calculate mean pixel value for fill color\n",
    "        mean = tuple(np.mean(img,axis=(0,1)).astype(int))\n",
    "    else:\n",
    "        mean = 0\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "    # Apply horizontal flip with 50% probability\n",
    "    if horizontal_flip and np.random.random() < 0.5:\n",
    "        img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    # Apply vertical flip with 50% probability\n",
    "    if vertical_flip and np.random.random() < 0.5:\n",
    "        img = img.transpose(Image.Transpose.FLIP_TOP_BOTTOM)\n",
    "\n",
    "    # Apply random rotation within the specified range\n",
    "    if rotation_range > 0:\n",
    "        rotation_range = np.random.randint(-rotation_range, rotation_range)\n",
    "        img = img.rotate(rotation_range, resample=Image.BICUBIC,fillcolor=mean)\n",
    "\n",
    "    # Apply random shifts\n",
    "    if horizontal_shift > 0 or vertical_shift > 0:\n",
    "        w , h = img_size\n",
    "        dw = np.random.randint(-horizontal_shift * w, horizontal_shift * w)\n",
    "        dh = np.random.randint(-vertical_shift * h, vertical_shift * h)\n",
    "        img = ImageOps.expand(img, border=(abs(dw),abs(dh),abs(dw),abs(dh)),fill=mean)\n",
    "        img = img.crop((dw+abs(dw),dh+abs(dh),dw+abs(dw)+w,dh+abs(dh)+h))\n",
    "    # Ensure the image is resized back to the original dimensions\n",
    "    img = img.resize(img_size)\n",
    "\n",
    "    # Convert image back to numpy array and normalize pixel values\n",
    "    img = np.array(img).astype(np.float32) / 255.0\n",
    "    return img"
   ],
   "id": "c4cf5cf014e66c35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 29,
   "source": [
    "# Going through all images and augment them\n",
    "def augment_loop(X_train,y_train,pattern,img_size=(224,224),horizontal_flip=True,vertical_flip=False,rotation_range=20, horizontal_shift=0.2, vertical_shift=0.2):\n",
    "    '''\n",
    "    Apply augmentation to the training dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (numpy array): Training images.\n",
    "    - y_train (numpy array): Training labels.\n",
    "    - pattern (str): Normalization pattern used.\n",
    "    - img_size (tuple): Desired output image size.\n",
    "    - Other parameters: Augmentation options.\n",
    "\n",
    "    Returns:\n",
    "    - X_train (numpy array): Augmented training images.\n",
    "    - y_train (numpy array): Corresponding labels.\n",
    "    '''\n",
    "    \n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    for img, label in zip(X_train,y_train):\n",
    "        X_augmented.append(img) # Original image\n",
    "        img = augmentation(img,pattern,img_size,horizontal_flip,vertical_flip,rotation_range, horizontal_shift, vertical_shift)\n",
    "        X_augmented.append(img) # Augmented image\n",
    "        y_augmented.append(label)\n",
    "        y_augmented.append(label)\n",
    "    del img, label\n",
    "    gc.collect()\n",
    "    X_train = np.array(X_augmented)\n",
    "    y_train = np.array(y_augmented)\n",
    "    return X_train, y_train"
   ],
   "id": "534b95b9ea2a1ec9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "22a959203a580210"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DL",
   "id": "e8e5a5e9a46a7c9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Visualization",
   "id": "6567950426bb36b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_accuracy(loader, model, device):\n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def get_losses(losses,loader, model, device):\n",
    "    loss = 0.0\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            l = criterion(outputs, targets)\n",
    "            loss += l.item()\n",
    "    loss /= len(loader)\n",
    "    losses.append(loss)\n",
    "    return losses\n",
    "\n",
    "def get_predictions(loader, model, device):\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    model.eval() \n",
    "    # for epoch in range(epoches):\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    return all_targets,all_predictions\n",
    "\n",
    "# Plot loss curve and confusion matrix for NNs\n",
    "def loss_curve(epoches,train_losses,val_losses,model = ''):\n",
    "    folder_path = os.path.join('results',model)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    # loss curve\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, epoches + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, epoches + 1), val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Testing Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(folder_path,'Loss_Curve.png'))\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,all_test_targets,all_test_predictions,model = ''):\n",
    "    folder_path = os.path.join('results',model)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "    plt.figure(figsize=(18, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    # calculate confusion matrix\n",
    "    cm = confusion_matrix(all_train_targets, all_train_predictions)\n",
    "    # plot confusion matrix\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix - Train')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    # calculate confusion matrix\n",
    "    cm = confusion_matrix(all_val_targets, all_val_predictions)\n",
    "    # plot confusion matrix\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix - Val')\n",
    "\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # calculate confusion matrix\n",
    "    cm = confusion_matrix(all_test_targets, all_test_predictions)\n",
    "    # plot confusion matrix\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix - Test')\n",
    "    \n",
    "    plt.savefig(os.path.join(folder_path,'Confusion_Matrix.png'))\n",
    "    plt.show()\n",
    "    \n",
    "def print_confusion_matrix(all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,all_test_targets,all_test_predictions,model = ''):\n",
    "    folder_path = os.path.join('results',model)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    report_train = classification_report(all_train_targets,all_train_predictions)\n",
    "    report_val = classification_report(all_val_targets,all_val_predictions)\n",
    "    report_test = classification_report(all_test_targets,all_test_predictions)\n",
    "    with open(os.path.join(folder_path,'report.txt'), 'w') as f:\n",
    "        f.write(\"\\nreport_train\\n\")\n",
    "        f.write(report_train)\n",
    "        f.write(\"\\nreport_val\\n\")\n",
    "        f.write(report_val)\n",
    "        f.write(\"\\nreport_test\\n\")\n",
    "        f.write(report_test)"
   ],
   "id": "ae0a765167bdbe52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataloader",
   "id": "a9873f74f18fd6da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.data[idx],dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx],dtype=torch.long)\n",
    "        \n",
    "        return image, label"
   ],
   "id": "28e8626741616bf2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CNN",
   "id": "7dcdf8504256a166"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,image_size=(3,224,224), num_classes=2,dropout = 0.25):\n",
    "        super(CNN, self).__init__()\n",
    "        c,h,w = image_size\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        # self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        # self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.flattened_size = 128 * (h // 4) * (w // 4) \n",
    "        self.fc = nn.Linear(self.flattened_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        # x = self.bn3(self.conv3(x))\n",
    "        # x = self.pool(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "619a7983c8b1c8ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pattern = 'Minmax'\n",
    "X,y = preprocess(df,pattern)\n",
    "X , y = random_sample(X,y)\n",
    "X_train, X_val, X_test, y_train, y_val,y_test = random_split(X,y)\n",
    "X_train, y_train = augment_loop(X_train,y_train,pattern)"
   ],
   "id": "18220937296f2ca8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = X_train.transpose(0,3,1,2)\n",
    "X_val = X_val.transpose(0,3,1,2)\n",
    "X_test = X_test.transpose(0,3,1,2)\n",
    "X_train.shape"
   ],
   "id": "681cd16e5d4c85a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(2024)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "CNN = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(CNN.parameters(),lr=0.01,weight_decay=1e-4)\n",
    "\n",
    "epoches = 50\n",
    "best_val_accuracy = 0\n",
    "datas = []\n",
    "val_datas = []\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "dataset = ImageDataset(X_train,y_train)\n",
    "val_dataset = ImageDataset(X_val,y_val)\n",
    "test_dataset = ImageDataset(X_test,y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    CNN.train()\n",
    "       \n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = CNN(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_accuracy = calculate_accuracy(train_loader, CNN, device)\n",
    "    val_accuracy = calculate_accuracy(val_loader, CNN, device)\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{epoches}], \"\n",
    "          f\"Loss: {loss.item() / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Test Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(CNN.state_dict(), 'best_model_CNN.pth')\n",
    "    \n",
    "    train_losses = get_losses(train_losses,train_loader, CNN, device)\n",
    "    val_losses = get_losses(val_losses,val_loader, CNN, device)\n",
    "\n"
   ],
   "id": "61604aa0a85baf35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate model\n",
    "CNN.load_state_dict (torch.load('best_model_CNN.pth'))\n",
    "\n",
    "all_train_targets = []\n",
    "all_train_predictions = []\n",
    "\n",
    "all_train_targets,all_train_predictions = get_predictions(train_loader, CNN, device)\n",
    "\n",
    "all_val_targets = []\n",
    "all_val_predictions = []\n",
    "\n",
    "all_val_targets,all_val_predictions = get_predictions(val_loader, CNN, device)\n",
    "\n",
    "all_test_targets = []\n",
    "all_test_predictions = []\n",
    "\n",
    "all_test_targets,all_test_predictions = get_predictions(test_loader, CNN, device)\n",
    "\n",
    "# loss curve\n",
    "loss_curve(epoches, train_losses, val_losses,model = 'CNN')\n",
    "\n",
    "plot_confusion_matrix(all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,all_test_targets,all_test_predictions,model = 'CNN')\n",
    "\n"
   ],
   "id": "d3196e6617dc2875"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print_confusion_matrix(all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,all_test_targets,all_test_predictions,model = 'CNN')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "6a1737a2b1ca972e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Resnet18",
   "id": "3e5655afb7408f51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pattern = 'Zscore'\n",
    "X,y = preprocess(df,pattern,default=True)\n",
    "# X , y = random_sample(X,y)\n",
    "X_train, X_val, X_test, y_train, y_val,y_test = random_split(X,y)\n",
    "# X_train, y_train = augment_loop(X_train,y_train,pattern)"
   ],
   "id": "df35244d23521d4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = X_train.transpose(0,3,1,2)\n",
    "X_val = X_val.transpose(0,3,1,2)\n",
    "X_test = X_test.transpose(0,3,1,2)\n",
    "X_train.shape"
   ],
   "id": "134ed891ee90af6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(2024)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "Resnet18 = models.resnet18(pretrained=True)\n",
    "Resnet18.fc = nn.Linear(Resnet18.fc.in_features, 2)  # Binary classification (0 and 1)\n",
    "Resnet18 = Resnet18.to(device)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device))\n",
    "optimizer = optim.Adam(Resnet18.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "epoches = 50\n",
    "best_val_accuracy = 0\n",
    "datas = []\n",
    "val_datas = []\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "dataset = ImageDataset(X_train,y_train)\n",
    "val_dataset = ImageDataset(X_val,y_val)\n",
    "test_dataset = ImageDataset(X_test,y_test)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "   \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    Resnet18.train()   \n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = Resnet18(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_accuracy = calculate_accuracy(train_loader, Resnet18, device)\n",
    "    val_accuracy = calculate_accuracy(val_loader, Resnet18, device)\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{epoches}], \"\n",
    "          f\"Loss: {loss.item() / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Test Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(Resnet18.state_dict(), 'best_model_resnet18.pth')\n",
    "    \n",
    "    train_losses = get_losses(train_losses,train_loader, Resnet18, device)\n",
    "    val_losses = get_losses(val_losses,val_loader, Resnet18, device)\n"
   ],
   "id": "eb5f580c380c7942"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate model\n",
    "Resnet18.load_state_dict (torch.load('best_model_resnet18.pth'))\n",
    "\n",
    "all_train_targets = []\n",
    "all_train_predictions = []\n",
    "\n",
    "all_train_targets,all_train_predictions = get_predictions(train_loader, Resnet18, device)\n",
    "\n",
    "all_val_targets = []\n",
    "all_val_predictions = []\n",
    "\n",
    "all_val_targets,all_val_predictions = get_predictions(val_loader, Resnet18, device)\n",
    "\n",
    "all_test_targets = []\n",
    "all_test_predictions = []\n",
    "\n",
    "all_test_targets,all_test_predictions = get_predictions(test_loader, Resnet18, device)\n",
    "\n",
    "# loss curve\n",
    "loss_curve(epoches, train_losses, val_losses,model = 'Resnet18')\n",
    "\n",
    "plot_confusion_matrix(all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,all_test_targets,all_test_predictions,model = 'Resnet18')\n",
    "\n"
   ],
   "id": "8d0e845a69e89fb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print_confusion_matrix(all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,all_test_targets,all_test_predictions,model = 'Resnet18')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "19232b8e6c0162c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a383e3374119b22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f95c4b9aac88f831"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pattern = 'Zscore'\n",
    "X,y = preprocess(df,pattern,default=True)\n",
    "# X , y = random_sample(X,y)\n",
    "X_train, X_val, X_test, y_train, y_val,y_test = random_split(X,y)\n",
    "X_train, y_train = augment_loop(X_train,y_train,pattern)"
   ],
   "id": "6ddc5153a3f7c44f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = X_train.transpose(0,3,1,2)\n",
    "X_val = X_val.transpose(0,3,1,2)\n",
    "X_test = X_test.transpose(0,3,1,2)\n",
    "X_train.shape"
   ],
   "id": "e99972f3bf707485"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(2024)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "Resnet18 = models.resnet18(pretrained=True)\n",
    "Resnet18.fc = nn.Linear(Resnet18.fc.in_features, 2)  # Binary classification (0 and 1)\n",
    "Resnet18 = Resnet18.to(device)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor.to(device))\n",
    "optimizer = optim.Adam(Resnet18.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "epoches = 50\n",
    "best_val_accuracy = 0\n",
    "datas = []\n",
    "val_datas = []\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "dataset = ImageDataset(X_train,y_train)\n",
    "val_dataset = ImageDataset(X_val,y_val)\n",
    "test_dataset = ImageDataset(X_test,y_test)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "   \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    Resnet18.train()   \n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = Resnet18(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_accuracy = calculate_accuracy(train_loader, Resnet18, device)\n",
    "    val_accuracy = calculate_accuracy(val_loader, Resnet18, device)\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{epoches}], \"\n",
    "          f\"Loss: {loss.item() / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Test Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(Resnet18.state_dict(), 'best_model_resnet18_aug.pth')\n",
    "    \n",
    "    train_losses = get_losses(train_losses,train_loader, Resnet18, device)\n",
    "    val_losses = get_losses(val_losses,val_loader, Resnet18, device)\n"
   ],
   "id": "ed7e9a6e9e41a362"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate model\n",
    "Resnet18.load_state_dict (torch.load('best_model_resnet18_aug.pth'))\n",
    "\n",
    "all_train_targets = []\n",
    "all_train_predictions = []\n",
    "\n",
    "all_train_targets,all_train_predictions = get_predictions(train_loader, Resnet18, device)\n",
    "\n",
    "all_val_targets = []\n",
    "all_val_predictions = []\n",
    "\n",
    "all_val_targets,all_val_predictions = get_predictions(val_loader, Resnet18, device)\n",
    "\n",
    "all_test_targets = []\n",
    "all_test_predictions = []\n",
    "\n",
    "all_test_targets,all_test_predictions = get_predictions(test_loader, Resnet18, device)\n",
    "\n",
    "# loss curve\n",
    "loss_curve(epoches, train_losses, val_losses,model = 'Resnet18_aug')\n",
    "\n",
    "plot_confusion_matrix(all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,all_test_targets,all_test_predictions,model = 'Resnet18_aug')\n",
    "\n"
   ],
   "id": "c94bed5a8aa3ff82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print_confusion_matrix(all_train_targets,all_train_predictions,all_val_targets,all_val_predictions,all_test_targets,all_test_predictions,model = 'Resnet18_aug')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "25c6612268351368"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
